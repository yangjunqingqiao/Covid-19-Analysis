{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bitcovidcondaf748f7fd555e4e6a9b666205bb9dac0b",
   "display_name": "Python 3.8.2 64-bit ('covid': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets historical weather data from WunderGround\n",
    "# Using BeautifulSoup and Selenium to get the monthly weather stats\n",
    "\n",
    "import requests, sys, re\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium.webdriver.common.keys import Keys\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(html, attempt=0, threshold=10):\n",
    "    page = requests.get(html)\n",
    "    try: \n",
    "        assert(199 < page.status_code < 300)\n",
    "        return page\n",
    "    except AssertionError:\n",
    "        if attempt < threshold:\n",
    "            return get_page(html, attempt + 1, threshold=threshold)\n",
    "        else:\n",
    "            raise Exception('Exceeded maximum attempts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.wunderground.com/history/monthly/KLGA/date/2020-3'\n",
    "\n",
    "bi = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\\\firefox.exe')\n",
    "br = webdriver.Firefox(firefox_binary=bi)\n",
    "\n",
    "br.get(url)\n",
    "\n",
    "# soup = bs(br.page_source, 'html.parser')\n",
    "soup = bs(br.page_source, 'lxml')\n",
    "\n",
    "br.quit()\n",
    "\n",
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all the tables into csv files:\n",
    "for i in range(len(tables)):\n",
    "    out_file = open('wunderground' + str(i + 1) + '.csv', 'w')\n",
    "    table = tables[i]\n",
    "\n",
    "    # ---- Write the table header: ----\n",
    "    table_head = table.findAll('th')\n",
    "    output_head = []\n",
    "    for head in table_head:\n",
    "        output_head.append(head.text.strip())\n",
    "\n",
    "    # Some cleaning and formatting of the text before writing:\n",
    "    header = '\"' + '\";\"'.join(output_head) + '\"'\n",
    "    header = re.sub('\\s', '', header) + '\\n'\n",
    "    out_file.write(header)\n",
    "\n",
    "    # ---- Write the rows: ----\n",
    "    output_rows = []\n",
    "    rows = table.findAll('tr')\n",
    "    for j in range(1, len(rows)):\n",
    "        table_row = rows[j]\n",
    "        columns = table_row.findAll('td')\n",
    "        output_row = []\n",
    "        for column in columns:\n",
    "            output_row.append(column.text.strip())\n",
    "\n",
    "        # Some cleaning and formatting of the text before writing:\n",
    "        fila = '\"' + '\";\"'.join(output_row) + '\"'\n",
    "        fila = re.sub('\\s', '', fila) + '\\n'\n",
    "        out_file.write(fila)\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}